{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IMDB 영화평 감성분석"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"5814_8\"</td>\n      <td>1</td>\n      <td>\"With all this stuff going down at the moment ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"2381_9\"</td>\n      <td>1</td>\n      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"7759_3\"</td>\n      <td>0</td>\n      <td>\"The film starts with a manager (Nicholas Bell...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('../00.data/IMDB/labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25000 entries, 0 to 24999\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   id         25000 non-null  object\n 1   sentiment  25000 non-null  int64 \n 2   review     25000 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally sta'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.review[0][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <br /> 태그는 공백으로 변환\n",
    "df['review'] = df.review.str.replace('<br />', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 이외의 문자는 공백으로 변환(숫자 등)\n",
    "# 앞에 들어가는 ^는 not의 의미 -> a-z, A-Z가 '아닌 놈들은' 공백으로 바꿔라\n",
    "import re\n",
    "\n",
    "df['review'] = df.review.apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((17500, 1), (7500, 1))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_df = df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature_df, df.sentiment, test_size =0.3, random_state=156\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "source": [
    "- CountVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "count_vect.fit(X_train.review)\n",
    "X_train_count = count_vect.transform(X_train.review)\n",
    "X_test_count = count_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_count, y_train)\n",
    "pred = lr_clf.predict(X_test_count)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "- TfidfVectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "tfidf_vect.fit(X_train.review)\n",
    "X_train_tfidf = tfidf_vect.transform(X_train.review)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=10)\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "### Model 저장하고 불러오기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/imdb_lr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(tfidf_vect, 'model/imdb_vect.pkl')\n",
    "joblib.dump(lr_clf, 'model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수지우기\n",
    "del tfidf_vect\n",
    "del lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vect = joblib.load('model/imdb_vect.pkl')\n",
    "new_lr = joblib.load('model/imdb_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test = new_vect.transform(X_test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8936"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "pred = new_lr.predict(new_X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "source": [
    "- 모델을 저장하고 불러오기로 사용하면, 이후에 모델을 재사용 할 때에 보다 시간을 save 할 수 있다.\n",
    "- web 프로그램을 만드는경우, 이미 만들어놓은 파일을 디스크로 만들어 화면에 표시가하고, 그에 따라 훈련시킨 모델로 긍정/부정의 평가를 내리면 된다.\n",
    "- 그렇기때문에, save-load의 과정은 꼭 갖고가는것이 좋다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Pipeline을 써서 학습/예측/평가"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count Vectorizer + Logistic Regression 정확도 : 0.8860\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer(stop_words='english', ngram_range=(1,2))), ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train.review, y_train)\n",
    "pred = pipeline.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logistic Regression 정확도 : {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/pipline.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'model/pipline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipe = joblib.load('model/pipline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count Vectorizer + Logistic Regression 정확도 : 0.8860\n"
     ]
    }
   ],
   "source": [
    "pred = new_pipe.predict(X_test.review)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "print(f'Count Vectorizer + Logistic Regression 정확도 : {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  4.7min finished\n",
      "{'count_vect__max_df': 700, 'lr_clf__C': 1} 0.8736571714181699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'count_vect__max_df': [300, 700],\n",
    "    'lr_clf__C': [1, 10]\n",
    "}\n",
    "\n",
    "grid_pipe = GridSearchCV(new_pipe, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 11.4min finished\n",
      "{'count_vect__max_df': 1000, 'lr_clf__C': 1} 0.8782860269423692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'count_vect__max_df': [500,700,1000],\n",
    "    'lr_clf__C': [1, 10, 20]\n",
    "}\n",
    "\n",
    "grid_pipe = GridSearchCV(new_pipe, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 11.7min finished\n",
      "{'count_vect__max_df': 900, 'lr_clf__C': 10} 0.8764573901994654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'count_vect__max_df': [500,700,900],\n",
    "    'lr_clf__C': [10,20,30]\n",
    "}\n",
    "S\n",
    "grid_pipe = GridSearchCV(new_pipe, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train.review, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}